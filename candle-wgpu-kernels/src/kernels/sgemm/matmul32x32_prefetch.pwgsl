// const TSM : u32 = 32u;                
// const TSN : u32 = 32u;                
// const TSK : u32 = 16u;                 
// const WPTM : u32 = 2u;                 
// const WPTN : u32 = 2u;                 

#define TSM 32u                     // The tile-size in dimension M
#define TSN 32u                     // The tile-size in dimension N
#define TSK 32u                     // The tile-size in dimension K
#define WPTM 2u                     // The work-per-thread in dimension M
#define WPTN 2u                     // The work-per-thread in dimension N
#define PREFETCH 2u

// const RTSM : u32 = (TSM/WPTM); //16        // The reduced tile-size in dimension M
// const RTSN : u32 = (TSN/WPTN); //16       // The reduced tile-size in dimension N
// const LPTA : u32 = ((TSK*TSM)/(RTSM*RTSN)); //8 Loads-per-thread for A
// const LPTB : u32 = ((TSK*TSN)/(RTSM*RTSN)); //8 Loads-per-thread for B

//const PREFETCH : u32 = 2u; //no prefetch

#include "matmulHelper.pwgsl"

@compute @workgroup_size(RTSN, RTSM, 1)
//MxK * KxN = MxN
fn matmul(@builtin(workgroup_id) group_id: vec3<u32>, @builtin(local_invocation_id) local_id: vec3<u32>) {
    generic_sgemm(group_id, local_id);
}

@compute @workgroup_size(RTSN, RTSM, 1)
//MxK * KxN = MxN
fn matmul_no_padded(@builtin(workgroup_id) group_id: vec3<u32>, @builtin(local_invocation_id) local_id: vec3<u32>) {
    generic_sgemm(group_id, local_id);
    //generic_sgemm_no_padded(group_id, local_id);
}